{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"04 Dataset and DataLoader Update 04 Dataset and DataLoader.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNUkUJX3n4Qhrf295niqPiY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"egGcPN7pitS3","colab_type":"code","colab":{}},"source":["!nvidia-smi\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","path = '/content/drive/My Drive'\n","os.chdir(path)\n","os.listdir(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"snz1julSijX5","colab_type":"code","colab":{}},"source":["#Epoch: One forward pass and one backward pass of all the training examples(所有数据完成一次训练)\n","#Batch-Size: The number of training examples in one forward backward pass.(每次参数更新使用的样本数量，一个Epoch常分割为几个Batch)\n","#Iteration: Number of passes, each pass using [batch size] number of examples. (一个Epoch迭代的次数，即Batch的个数。10000条数据，Batch-size为1000的话，Iteration为10)\n","#shuffle=True 增加随机性打乱顺序\n","\n","import torch\n","from torch.utils.data import Dataset #Dateset是抽象类(abstract class)，无法直接实例化，只可创建子类继承后，实例化子类\n","from torch.utils.data import DataLoader #加载数据，shuffle打乱数据,分Batch\n","import numpy as np\n","\n","\n","class DiabetesDataset(Dataset):\n","  def __init__(self, filepath):\n","    xy = np.loadtxt(filepath, delimiter=',' , dtype=np.float32, skiprows = 1)\n","    '''\n","    loadtxt(fname,                  #要读取的文件、文件名、或生成器。\n","            dtype=<class 'float'>,  #数据类型，默认float。\n","            comments='#',           #注释\n","            delimiter=None,         #分隔符，默认是空格。\n","            converters=None, \n","            skiprows=0,             #跳过前几行读取，默认是0，必须是int整型。\n","            usecols=None,           #要读取哪些列，0是第一列。例如，usecols = （1,4,5）将提取第2，第5和第6列。默认读取所有列。\n","            unpack=False,           #如果为True，将分列读取。\n","            ndmin=0)\n","    '''\n","    self.len = xy.shape[0]#取出数据集的第一个纬度，即有几行数据，数据的条数。这里数据集的纬度为(n*9)，第一个纬度为n\n","    self.x_data = torch.from_numpy(xy[:, :-1])#取所有行，除最后一列外的所有列\n","    self.y_data = torch.from_numpy(xy[:, [-1]])#取所有行，最后一列\n","  \n","  #支持下标index操作 dataset[index]\n","  def __getitem__(self,index):\n","    return self.x_data[index],self.y_data[index]\n","  \n","  #返回数据集内的数据条数\n","  def __len__(self):\n","    return self.len\n","\n","\n","class Model(torch.nn.Module):\n","  def __init__(self):\n","    super(Model,self).__init__()\n","    self.linear1 = torch.nn.Linear(8,6)\n","    self.linear2 = torch.nn.Linear(6,4)\n","    self.linear3 = torch.nn.Linear(4,1)\n","    #构建一个3层网络，神经元数量分别为8,6,4。整体上为输入一个8纬特征，输出一个二分类结果\n","    \n","    self.activate = torch.nn.ReLU()\n","    #创建激活函数模块，直接可在下方forward用self调用\n","    self.sigmoid = torch.nn.Sigmoid()\n","\n","  def forward(self, x):\n","    x = self.activate(self.linear1(x))\n","    x = self.activate(self.linear2(x))\n","    x = self.sigmoid(self.linear3(x))\n","    #最后一层输出，为计算loss，由ReLU改为sigmoid\n","    return x\n","\n","\n","dataset = DiabetesDataset('./Colab Notebooks/dataset/diabetes.csv')\n","train_loader = DataLoader(dataset = dataset,#传递数据集\n","                          batch_size = 32,  \n","                          shuffle = True,\n","                          num_workers = 2)  #读取数据时，并行的进行数量\n","\n","model = Model()\n","criterion = torch.nn.BCELoss(size_average=True)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n","\n","\n","loss_list = []\n","epoch = 10\n","for i in range(epoch):\n","  for j,data in enumerate(train_loader):\n","    inputs,labels = data \n","    y_pred = model(inputs)\n","    loss = criterion(y_pred,labels)\n","\n","    loss_list.append(loss)\n","    #print(i,loss)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    #print('----------------------------------------------')\n","\n","\n","plt.plot(range(epoch*24),loss_list) #768条数据，batch_size32,一个epoch分为24组\n","plt.xlabel('batch')\n","plt.ylabel('loss')\n","plt.show()\n"],"execution_count":null,"outputs":[]}]}
